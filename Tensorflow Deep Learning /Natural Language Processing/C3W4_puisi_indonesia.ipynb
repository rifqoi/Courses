{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "C3W4_puisi_indonesia.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T18:28:26.033922Z",
          "iopub.execute_input": "2022-04-08T18:28:26.034110Z",
          "iopub.status.idle": "2022-04-08T18:28:31.374729Z",
          "shell.execute_reply.started": "2022-04-08T18:28:26.034085Z",
          "shell.execute_reply": "2022-04-08T18:28:31.373952Z"
        },
        "trusted": true,
        "id": "yrQPhlf7c3oc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./puisi.csv')\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T18:28:31.376246Z",
          "iopub.execute_input": "2022-04-08T18:28:31.376497Z",
          "iopub.status.idle": "2022-04-08T18:28:31.629152Z",
          "shell.execute_reply.started": "2022-04-08T18:28:31.376463Z",
          "shell.execute_reply": "2022-04-08T18:28:31.628420Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "gMGZCO95c3of",
        "outputId": "8aa88e44-913f-474b-e3e4-63e246a71012"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  puisi                 title  \\\n",
              "0     Tiada lagi resah di hatiku \\n Tiada lagi kerag...       UNTUK KEKASIHKU   \n",
              "1     Gemericik senandung luluh merayu hati, \\n Terj...                 HUJAN   \n",
              "2     Kau adalah separuh hidup ku \\n Hanya kepadamu ...                   KAU   \n",
              "3     Mungkin kau membiarkan aku \\n Membiarkan peras...           TEPERANGKAP   \n",
              "4     Ibu.. \\n Kau adalah mutiara hatiku \\n Mutiara ...                   IBU   \n",
              "...                                                 ...                   ...   \n",
              "7218  Rasa kangen ini \\n Tak pernah terharap sedikit...  BUKAN PILIHAN HATIMU   \n",
              "7219  Dititik manakah aku berada,. \\n Dalam jiwamu h...                 TANYA   \n",
              "7220  Semoga apa yang kau inginkanakan terjadi dimas...                  AYAH   \n",
              "7221  Sahabat..... \\n Maafkan aku Setelah Di sekolah...  SAHABAT YANG TERLUKA   \n",
              "7222  Ibu. \\n Pengorbananmu adalah suatu cerminan ba...     BUNDAKU TERSAYANG   \n",
              "\n",
              "                          author  \\\n",
              "0       Oleh Suzianty Westerveld   \n",
              "1         Oleh Muslihin Abdillah   \n",
              "2           Oleh Nur Rahma Utami   \n",
              "3      Oleh Mangku Langit Jingga   \n",
              "4     Oleh Dedeh Kurnia Afrianti   \n",
              "...                          ...   \n",
              "7218           Oleh Arshya Kyran   \n",
              "7219     Oleh Wahyu Dwi Septiaji   \n",
              "7220                 Oleh Kendra   \n",
              "7221                  Oleh Mutia   \n",
              "7222                Oleh Antonio   \n",
              "\n",
              "                                      puisi_with_header  \n",
              "0     UNTUK KEKASIHKU \\n Oleh Suzianty Westerveld \\n...  \n",
              "1     HUJAN \\n Oleh Muslihin Abdillah \\n  \\n Gemeric...  \n",
              "2     KAU \\n Oleh Nur Rahma Utami \\n Kau adalah sepa...  \n",
              "3     TEPERANGKAP \\n Oleh Mangku Langit Jingga \\n  \\...  \n",
              "4     IBU \\n Oleh Dedeh Kurnia Afrianti \\n  \\n Ibu.....  \n",
              "...                                                 ...  \n",
              "7218  BUKAN PILIHAN HATIMU \\n Oleh Arshya Kyran \\n  ...  \n",
              "7219  TANYA \\n Oleh Wahyu Dwi Septiaji \\n  \\n Dititi...  \n",
              "7220  AYAH \\n Oleh Kendra \\n Semoga apa yang kau ing...  \n",
              "7221  SAHABAT YANG TERLUKA \\n Oleh Mutia \\n  \\n Saha...  \n",
              "7222  BUNDAKU TERSAYANG \\n Oleh Antonio \\n  \\n Ibu. ...  \n",
              "\n",
              "[7223 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-56dd56cc-1250-476a-935c-b6a6e6a49d9c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>puisi</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>puisi_with_header</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tiada lagi resah di hatiku \\n Tiada lagi kerag...</td>\n",
              "      <td>UNTUK KEKASIHKU</td>\n",
              "      <td>Oleh Suzianty Westerveld</td>\n",
              "      <td>UNTUK KEKASIHKU \\n Oleh Suzianty Westerveld \\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gemericik senandung luluh merayu hati, \\n Terj...</td>\n",
              "      <td>HUJAN</td>\n",
              "      <td>Oleh Muslihin Abdillah</td>\n",
              "      <td>HUJAN \\n Oleh Muslihin Abdillah \\n  \\n Gemeric...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kau adalah separuh hidup ku \\n Hanya kepadamu ...</td>\n",
              "      <td>KAU</td>\n",
              "      <td>Oleh Nur Rahma Utami</td>\n",
              "      <td>KAU \\n Oleh Nur Rahma Utami \\n Kau adalah sepa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mungkin kau membiarkan aku \\n Membiarkan peras...</td>\n",
              "      <td>TEPERANGKAP</td>\n",
              "      <td>Oleh Mangku Langit Jingga</td>\n",
              "      <td>TEPERANGKAP \\n Oleh Mangku Langit Jingga \\n  \\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ibu.. \\n Kau adalah mutiara hatiku \\n Mutiara ...</td>\n",
              "      <td>IBU</td>\n",
              "      <td>Oleh Dedeh Kurnia Afrianti</td>\n",
              "      <td>IBU \\n Oleh Dedeh Kurnia Afrianti \\n  \\n Ibu.....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7218</th>\n",
              "      <td>Rasa kangen ini \\n Tak pernah terharap sedikit...</td>\n",
              "      <td>BUKAN PILIHAN HATIMU</td>\n",
              "      <td>Oleh Arshya Kyran</td>\n",
              "      <td>BUKAN PILIHAN HATIMU \\n Oleh Arshya Kyran \\n  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7219</th>\n",
              "      <td>Dititik manakah aku berada,. \\n Dalam jiwamu h...</td>\n",
              "      <td>TANYA</td>\n",
              "      <td>Oleh Wahyu Dwi Septiaji</td>\n",
              "      <td>TANYA \\n Oleh Wahyu Dwi Septiaji \\n  \\n Dititi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7220</th>\n",
              "      <td>Semoga apa yang kau inginkanakan terjadi dimas...</td>\n",
              "      <td>AYAH</td>\n",
              "      <td>Oleh Kendra</td>\n",
              "      <td>AYAH \\n Oleh Kendra \\n Semoga apa yang kau ing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7221</th>\n",
              "      <td>Sahabat..... \\n Maafkan aku Setelah Di sekolah...</td>\n",
              "      <td>SAHABAT YANG TERLUKA</td>\n",
              "      <td>Oleh Mutia</td>\n",
              "      <td>SAHABAT YANG TERLUKA \\n Oleh Mutia \\n  \\n Saha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7222</th>\n",
              "      <td>Ibu. \\n Pengorbananmu adalah suatu cerminan ba...</td>\n",
              "      <td>BUNDAKU TERSAYANG</td>\n",
              "      <td>Oleh Antonio</td>\n",
              "      <td>BUNDAKU TERSAYANG \\n Oleh Antonio \\n  \\n Ibu. ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7223 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56dd56cc-1250-476a-935c-b6a6e6a49d9c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-56dd56cc-1250-476a-935c-b6a6e6a49d9c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-56dd56cc-1250-476a-935c-b6a6e6a49d9c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = df['puisi'][:100].astype(str)\n",
        "type(corpus[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T18:28:31.630480Z",
          "iopub.execute_input": "2022-04-08T18:28:31.630754Z",
          "iopub.status.idle": "2022-04-08T18:28:31.640684Z",
          "shell.execute_reply.started": "2022-04-08T18:28:31.630717Z",
          "shell.execute_reply": "2022-04-08T18:28:31.639836Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t99rC01Nc3oh",
        "outputId": "76334ce3-069c-41d8-b069-18292e3cefa6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Tokenizer class\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Generate the word index dictionary\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "# Define the total words. You add 1 for the index `0` which is just the padding token.\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(f'word index dictionary: {list(tokenizer.word_index.keys())[:5]} {list(tokenizer.word_index.values())[:5]}')\n",
        "print(f'total words: {total_words}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T18:28:31.642877Z",
          "iopub.execute_input": "2022-04-08T18:28:31.643562Z",
          "iopub.status.idle": "2022-04-08T18:28:32.305986Z",
          "shell.execute_reply.started": "2022-04-08T18:28:31.643519Z",
          "shell.execute_reply": "2022-04-08T18:28:32.305254Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AG4oGLlc3oj",
        "outputId": "df7af3a0-65ca-4e1e-ca2b-f8335fefd301"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word index dictionary: ['yang', 'aku', 'tak', 'kau', 'dan'] [1, 2, 3, 4, 5]\n",
            "total words: 2879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the sequences list\n",
        "input_sequences = []\n",
        "\n",
        "# Loop over every line\n",
        "for line in corpus:\n",
        "\n",
        "    # Tokenize the current line\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\n",
        "    # Loop over the line several times to generate the subphrases\n",
        "    for i in range(1, len(token_list)):\n",
        "\n",
        "        # Generate the subphrase\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "\n",
        "        # Append the subphrase to the sequences list\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Get the length of the longest line\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "# Pad all sequences\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Create inputs and label by splitting the last token in the subphrases\n",
        "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "# Convert the label into one-hot arrays\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T18:28:41.010789Z",
          "iopub.execute_input": "2022-04-08T18:28:41.011302Z",
          "iopub.status.idle": "2022-04-08T18:28:53.752118Z",
          "shell.execute_reply.started": "2022-04-08T18:28:41.011267Z",
          "shell.execute_reply": "2022-04-08T18:28:53.751389Z"
        },
        "trusted": true,
        "id": "M4FwEeFyc3om"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(xs[0])\n",
        "print(labels[0])\n",
        "print(ys[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T18:29:08.224454Z",
          "iopub.execute_input": "2022-04-08T18:29:08.225333Z",
          "iopub.status.idle": "2022-04-08T18:29:08.233337Z",
          "shell.execute_reply.started": "2022-04-08T18:29:08.225277Z",
          "shell.execute_reply": "2022-04-08T18:29:08.232473Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKu3zHxsc3op",
        "outputId": "a22a2c7b-c2a9-43db-a7b4-b7491d5fda3c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 71]\n",
            "54\n",
            "[0. 0. 0. ... 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get sample sentence\n",
        "sentence = corpus[0].split()\n",
        "print(f'sample sentence: {sentence}')\n",
        "\n",
        "# Initialize token list\n",
        "token_list = []\n",
        "\n",
        "# Look up the indices of each word and append to the list\n",
        "for word in sentence: \n",
        "  token_list.append(tokenizer.word_index[word])\n",
        "\n",
        "# Print the token list\n",
        "print(token_list)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T18:29:29.751951Z",
          "iopub.execute_input": "2022-04-08T18:29:29.752204Z",
          "iopub.status.idle": "2022-04-08T18:29:30.012621Z",
          "shell.execute_reply.started": "2022-04-08T18:29:29.752174Z",
          "shell.execute_reply": "2022-04-08T18:29:30.011491Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "pFo780jwc3or",
        "outputId": "d2c886d1-bf33-46dd-c82e-2a09da0c6d58"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample sentence: ['Tiada', 'lagi', 'resah', 'di', 'hatiku', 'Tiada', 'lagi', 'keraguan', 'kini', 'Aku', 'yakin', 'hanyalah', 'dirimu', 'Yang', 'ku', 'sayangi', 'Setiap', 'langkah', 'akupunBerjanji.....................', 'Akan', 'selalau', 'setia', 'bersama', 'Kaulah', 'nafasku', 'Kaulah', 'khayalanku', 'Kaulah', 'damai', 'dalam', 'detak', 'jantungkuOh..............', 'kasih', 'Peluklah', 'diriku', 'Bisikanlah', 'apa', 'yang', 'kau', 'mauOh..............', 'kasih', 'Aku', 'tak', 'sanggup', 'lagi', 'Hidup', 'tanpa', 'dirimu']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-e48815fc0a01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Look up the indices of each word and append to the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mtoken_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Print the token list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Tiada'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick element\n",
        "elem_number = 4\n",
        "\n",
        "# Print token list and phrase\n",
        "print(f'token list: {xs[elem_number]}')\n",
        "print(f'decoded to text: {tokenizer.sequences_to_texts([xs[elem_number]])}')\n",
        "\n",
        "# Print label\n",
        "print(f'one-hot label: {ys[elem_number]}')\n",
        "print(f'index of label: {np.argmax(ys[elem_number])}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T18:30:17.310460Z",
          "iopub.execute_input": "2022-04-08T18:30:17.311164Z",
          "iopub.status.idle": "2022-04-08T18:30:17.318958Z",
          "shell.execute_reply.started": "2022-04-08T18:30:17.311125Z",
          "shell.execute_reply": "2022-04-08T18:30:17.318248Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NxEG264c3os",
        "outputId": "1d04002e-a1a3-47ab-c84a-cb3041d42c16"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token list: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0   71   54 1006    8   97]\n",
            "decoded to text: ['tiada lagi resah di hatiku']\n",
            "one-hot label: [0. 0. 0. ... 0. 0. 0.]\n",
            "index of label: 71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "embedding_dim = 100\n",
        "lstm_units = 150\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "          Embedding(total_words, embedding_dim, input_length=max_sequence_len-1),\n",
        "          Bidirectional(LSTM(lstm_units)),\n",
        "          Dense(total_words, activation='softmax')\n",
        "])\n",
        "\n",
        "# Use categorical crossentropy because this is a multi-class problem\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', \n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), \n",
        "    metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T18:30:23.989672Z",
          "iopub.execute_input": "2022-04-08T18:30:23.990122Z",
          "iopub.status.idle": "2022-04-08T18:30:26.712452Z",
          "shell.execute_reply.started": "2022-04-08T18:30:23.990084Z",
          "shell.execute_reply": "2022-04-08T18:30:26.711750Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuA1Suatc3ov",
        "outputId": "c9c445aa-bbd9-4645-cfd5-c4c66bf7221b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 526, 100)          287900    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 300)              301200    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2879)              866579    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,455,679\n",
            "Trainable params: 1,455,679\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(xs, ys, epochs=epochs)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T18:30:36.034071Z",
          "iopub.execute_input": "2022-04-08T18:30:36.034334Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QIGmun1c3ox",
        "outputId": "cdb87925-2ef0-4eb4-de6d-9f007d6ae0f2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "303/303 [==============================] - 63s 196ms/step - loss: 7.1885 - accuracy: 0.0346\n",
            "Epoch 2/20\n",
            "303/303 [==============================] - 59s 196ms/step - loss: 6.4432 - accuracy: 0.0515\n",
            "Epoch 3/20\n",
            "303/303 [==============================] - 59s 195ms/step - loss: 5.3537 - accuracy: 0.1041\n",
            "Epoch 4/20\n",
            "303/303 [==============================] - 59s 196ms/step - loss: 4.0031 - accuracy: 0.2126\n",
            "Epoch 5/20\n",
            "303/303 [==============================] - 59s 196ms/step - loss: 2.7207 - accuracy: 0.3940\n",
            "Epoch 6/20\n",
            "303/303 [==============================] - 59s 196ms/step - loss: 1.8782 - accuracy: 0.5581\n",
            "Epoch 7/20\n",
            "303/303 [==============================] - 59s 195ms/step - loss: 1.3104 - accuracy: 0.6834\n",
            "Epoch 8/20\n",
            "303/303 [==============================] - 59s 196ms/step - loss: 0.9394 - accuracy: 0.7621\n",
            "Epoch 9/20\n",
            "303/303 [==============================] - 59s 195ms/step - loss: 0.7374 - accuracy: 0.8066\n",
            "Epoch 10/20\n",
            "303/303 [==============================] - 59s 195ms/step - loss: 0.6328 - accuracy: 0.8309\n",
            "Epoch 11/20\n",
            "303/303 [==============================] - 59s 196ms/step - loss: 0.5431 - accuracy: 0.8552\n",
            "Epoch 12/20\n",
            "303/303 [==============================] - 59s 196ms/step - loss: 0.5267 - accuracy: 0.8609\n",
            "Epoch 13/20\n",
            "303/303 [==============================] - 60s 196ms/step - loss: 0.7433 - accuracy: 0.7935\n",
            "Epoch 14/20\n",
            "303/303 [==============================] - 59s 195ms/step - loss: 1.1245 - accuracy: 0.7003\n",
            "Epoch 15/20\n",
            "303/303 [==============================] - 59s 195ms/step - loss: 1.1253 - accuracy: 0.6987\n",
            "Epoch 16/20\n",
            "303/303 [==============================] - 59s 195ms/step - loss: 0.9075 - accuracy: 0.7534\n",
            "Epoch 17/20\n",
            "303/303 [==============================] - 59s 195ms/step - loss: 0.6509 - accuracy: 0.8199\n",
            "Epoch 18/20\n",
            "303/303 [==============================] - 59s 196ms/step - loss: 0.4450 - accuracy: 0.8715\n",
            "Epoch 19/20\n",
            "303/303 [==============================] - 59s 195ms/step - loss: 0.3710 - accuracy: 0.8962\n",
            "Epoch 20/20\n",
            "303/303 [==============================] - 59s 195ms/step - loss: 0.3185 - accuracy: 0.9089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define seed text\n",
        "seed_text = \"Pagi hari aku memakan nasi\"\n",
        "\n",
        "# Define total words to predict\n",
        "next_words = 20\n",
        "\n",
        "# Loop until desired length is reached\n",
        "for _ in range(next_words):\n",
        "\n",
        "  # Convert the seed text to a token sequence\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  \n",
        "  # Pad the sequence\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "  \n",
        "  # Feed to the model and get the probabilities for each index\n",
        "  probabilities = model.predict(token_list)\n",
        "  \n",
        "  # Get the index with the highest probability\n",
        "  predicted = np.argmax(probabilities, axis=-1)[0]\n",
        "  \n",
        "  # Ignore if index is 0 because that is just the padding.\n",
        "  if predicted != 0:\n",
        "    \n",
        "    # Look up the word associated with the index. \n",
        "    output_word = tokenizer.index_word[predicted]\n",
        "  \n",
        "    # Combine with the seed text\n",
        "    seed_text += \" \" + output_word\n",
        "  \n",
        "# Print the result\t\n",
        "print(seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqTlVIjwc3oz",
        "outputId": "f82774f0-5d2d-4f1d-d39b-b1bf1c7f298f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pagi hari aku memakan nasi dari berlalu telah terjadi sekian lama waktu masih memisahkan kita karena ia seakan akan telah pergi ketika selangkah ku jejaki\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1XT6AUymkxUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KxL1ZQrTkGOJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}